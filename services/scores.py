"""Scores-related DB helpers extracted from app.py to reduce module size."""
import datetime
import json
import os
import time
import traceback
from typing import Any, Dict, List, Optional

import mysql.connector

from common import app_logger
from db import get_db_connection


def parse_excel_file_url(excel_file_url):
    """
    è§£æexcel_file_urlå­—æ®µï¼Œå°†JSONæ ¼å¼è½¬æ¢ä¸ºæ•°ç»„æ ¼å¼
    æ”¯æŒå¤šç§æ ¼å¼ï¼š
    1. æ—§æ ¼å¼ï¼ˆå•ä¸ªURLå­—ç¬¦ä¸²ï¼‰: "https://..."
    2. æ—§æ ¼å¼ï¼ˆJSONå¯¹è±¡ï¼‰: {"æ–‡ä»¶å": "URL"}
    3. æ–°æ ¼å¼ï¼ˆå¸¦è¯´æ˜ä¸å­—æ®µæ˜ å°„ï¼‰: {"æ–‡ä»¶å": {"url": "URL", "description": "è¯´æ˜", "fields": ["è¯­æ–‡", ...]}}
    è¿”å›æ ¼å¼: [{"filename": "æ–‡ä»¶å", "url": "URL", "description": "è¯´æ˜", "fields": [...]}, ...]
    """
    if not excel_file_url:
        return []
    
    try:
        # å°è¯•è§£æä¸ºJSON
        if isinstance(excel_file_url, str):
            url_dict = json.loads(excel_file_url)
        else:
            url_dict = excel_file_url
        
        # å¦‚æœæ˜¯å­—å…¸æ ¼å¼
        if isinstance(url_dict, dict):
            result = []
            for filename, value in url_dict.items():
                # åˆ¤æ–­æ˜¯æ–°æ ¼å¼ï¼ˆå¯¹è±¡ï¼‰è¿˜æ˜¯æ—§æ ¼å¼ï¼ˆå­—ç¬¦ä¸²ï¼‰
                if isinstance(value, dict):
                    # æ–°æ ¼å¼: {"æ–‡ä»¶å": {"url": "URL", "description": "è¯´æ˜", "fields": []}}
                    result.append({
                        'filename': filename,
                        'url': value.get('url', ''),
                        'description': value.get('description', ''),
                        'fields': value.get('fields', []) or []
                    })
                else:
                    # æ—§æ ¼å¼: {"æ–‡ä»¶å": "URL"}
                    result.append({
                        'filename': filename,
                        'url': value,
                        'description': '',
                        'fields': []
                    })
            return result
        # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼ï¼ˆå¯èƒ½æœªæ¥æ‰©å±•ï¼‰
        elif isinstance(url_dict, list):
            # ç¡®ä¿æ¯ä¸ªå…ƒç´ éƒ½åŒ…å«å¿…éœ€å­—æ®µ
            normalized = []
            for item in url_dict:
                if isinstance(item, dict):
                    normalized.append({
                        'filename': item.get('filename', ''),
                        'url': item.get('url', ''),
                        'description': item.get('description', ''),
                        'fields': item.get('fields', []) or []
                    })
            return normalized
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ˆæ—§æ ¼å¼ï¼Œå•ä¸ªURLï¼‰
        elif isinstance(url_dict, str):
            return [{'filename': 'excel_file', 'url': url_dict, 'description': '', 'fields': []}]
        else:
            return []
    except (json.JSONDecodeError, TypeError, AttributeError):
        # å¦‚æœè§£æå¤±è´¥ï¼Œå¯èƒ½æ˜¯æ—§çš„å•ä¸ªURLæ ¼å¼
        if isinstance(excel_file_url, str):
            return [{'filename': 'excel_file', 'url': excel_file_url, 'description': '', 'fields': []}]
        return []


def save_student_scores(
    class_id: str,
    exam_name: Optional[str],
    term: Optional[str] = None,
    remark: Optional[str] = None,
    scores: List[Dict] = None,
    excel_file_url: Optional[str] = None,
    excel_file_name: Optional[str] = None,
    excel_file_description: Optional[str] = None,
    excel_files: Optional[List[Dict]] = None,
    operation_mode: str = 'append',
    fields: List[Dict] = None
) -> Dict[str, object]:
    """
    ä¿å­˜å­¦ç”Ÿæˆç»©è¡¨
    å‚æ•°è¯´æ˜ï¼š
    - class_id: ç­çº§IDï¼ˆå¿…éœ€ï¼‰
    - exam_name: è€ƒè¯•åç§°ï¼ˆå¿…éœ€ï¼Œå¦‚"æœŸä¸­è€ƒè¯•"ã€"æœŸæœ«è€ƒè¯•"ï¼‰
    - term: å­¦æœŸï¼ˆå¯é€‰ï¼Œå¦‚ '2025-2026-1'ï¼‰
    - remark: å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰
    - excel_file_url: Excelæ–‡ä»¶åœ¨OSSçš„URLï¼ˆå¯é€‰ï¼‰
    - excel_file_name: Excelæ–‡ä»¶åï¼ˆå¯é€‰ï¼Œç”¨äºç®¡ç†å¤šä¸ªæ–‡ä»¶ï¼‰
    - excel_file_description: Excelæ–‡ä»¶è¯´æ˜ï¼ˆå¯é€‰ï¼‰
    - operation_mode: æ“ä½œæ¨¡å¼ï¼Œ'append'ï¼ˆè¿½åŠ ï¼Œé»˜è®¤ï¼‰æˆ– 'replace'ï¼ˆæ›¿æ¢ï¼‰
    - fields: å­—æ®µå®šä¹‰åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
      {
        'field_name': str,      # å­—æ®µåç§°ï¼ˆå¿…éœ€ï¼‰
        'field_type': str,       # å­—æ®µç±»å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤'number'ï¼‰
        'field_order': int,      # å­—æ®µé¡ºåºï¼ˆå¯é€‰ï¼‰
        'is_total': int          # æ˜¯å¦ä¸ºæ€»åˆ†å­—æ®µï¼ˆå¯é€‰ï¼Œ0æˆ–1ï¼‰
      }
    - scores: æˆç»©æ˜ç»†åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
      {
        'student_id': str,      # å­¦å·ï¼ˆå¯é€‰ï¼‰
        'student_name': str,    # å§“åï¼ˆå¿…éœ€ï¼‰
        'chinese': int,         # è¯­æ–‡æˆç»©ï¼ˆå¯é€‰ï¼‰
        'math': int,            # æ•°å­¦æˆç»©ï¼ˆå¯é€‰ï¼‰
        'english': int,         # è‹±è¯­æˆç»©ï¼ˆå¯é€‰ï¼‰
        'total_score': float    # æ€»åˆ†ï¼ˆå¯é€‰ï¼Œå¯è‡ªåŠ¨è®¡ç®—ï¼‰
      }
    
    è¿”å›ï¼š
    - { success, score_header_id, inserted_count, updated_count, deleted_count, message }
    """
    if not class_id:
        return { 'success': False, 'score_header_id': None, 'inserted_count': 0, 'message': 'ç¼ºå°‘å¿…è¦å‚æ•° class_id' }

    # å…¼å®¹ï¼šexam_name ä¸å†ä½œä¸ºå®šä½æ¡ä»¶ï¼Œä½†è¡¨ç»“æ„ NOT NULLï¼Œä»éœ€å†™å…¥ä¸€ä¸ªå±•ç¤ºç”¨å­—ç¬¦ä¸²
    provided_exam_name = exam_name
    exam_name = (provided_exam_name or '').strip()
    if not exam_name:
        exam_name = 'æˆç»©'
    
    # éªŒè¯operation_mode
    if operation_mode not in ['append', 'replace']:
        operation_mode = 'append'  # é»˜è®¤ä½¿ç”¨è¿½åŠ æ¨¡å¼
    
    # åœ¨æ›¿æ¢æ¨¡å¼ä¸‹ï¼Œscoreså¯ä»¥ä¸ºç©ºï¼ˆç”¨äºåˆ é™¤æ‰€æœ‰æ•°æ®ï¼‰
    if operation_mode == 'replace' and (not scores or not isinstance(scores, list)):
        scores = []
    elif operation_mode == 'append' and (not scores or not isinstance(scores, list)):
        return { 'success': False, 'score_header_id': None, 'inserted_count': 0, 'message': 'æˆç»©æ˜ç»†åˆ—è¡¨ä¸èƒ½ä¸ºç©º' }

    app_logger.info(
        f"[save_student_scores] start class_id={class_id}, exam_name={exam_name}, term={term}, "
        f"operation_mode={operation_mode}, scores_count={len(scores) if scores else 0}"
    )
    
    connection = get_db_connection()
    if connection is None:
        error_msg = "Save student scores failed: Database connection error."
        print(f"[save_student_scores] é”™è¯¯: {error_msg}")
        app_logger.error(error_msg)
        return { 'success': False, 'score_header_id': None, 'inserted_count': 0, 'message': 'æ•°æ®åº“è¿æ¥å¤±è´¥' }

    try:
        connection.start_transaction()
        cursor = connection.cursor(dictionary=True)

        # é¢„å…ˆæ”¶é›†excelæ–‡ä»¶ä¸­çš„å­—æ®µï¼Œç”¨äºæ›¿æ¢æ¨¡å¼ä¸‹é¿å…è¯¯åˆ å…¶ä»–excelå¯¹åº”çš„å­—æ®µ
        keep_fields_from_excel_urls = set()  # æœ€ç»ˆç”¨äºä¿ç•™â€œå…¶ä»–â€Excelçš„å­—æ®µ
        other_excels_fields = set()          # å…¶ä»–Excelçš„å­—æ®µé›†åˆ
        current_excel_old_fields = set()     # æœ¬æ¬¡ä¸Šä¼ å¯¹åº”Excelåœ¨æ—§æ•°æ®ä¸­çš„å­—æ®µ
        current_excel_new_fields = set()     # æœ¬æ¬¡ä¸Šä¼ å¯¹åº”Excelåœ¨æ–°æ•°æ®ä¸­çš„å­—æ®µ
        uploaded_filenames = set()           # æœ¬æ¬¡ä¸Šä¼ æ¶‰åŠçš„æ–‡ä»¶å

        # 1. æ’å…¥æˆ–è·å–æˆç»©è¡¨å¤´
        # çº¦å®šï¼šclass_id + term èƒ½å®šä½ä¸€å¼ æˆç»©è¡¨ï¼›exam_name ä»…ä½œä¸ºå±•ç¤ºå­—æ®µä¿ç•™ï¼Œä¸ä½œä¸ºå®šä½æ¡ä»¶
        if term is None:
            cursor.execute(
                "SELECT id, excel_file_url "
                "FROM ta_student_score_header "
                "WHERE class_id = %s AND term IS NULL "
                "ORDER BY created_at DESC, updated_at DESC "
                "LIMIT 1",
                (class_id,)
            )
        else:
            cursor.execute(
                "SELECT id, excel_file_url "
                "FROM ta_student_score_header "
                "WHERE class_id = %s AND term = %s "
                "ORDER BY created_at DESC, updated_at DESC "
                "LIMIT 1",
                (class_id, term)
            )
        header_row = cursor.fetchone()

        if header_row is None:
            # æ’å…¥æ–°è¡¨å¤´
            app_logger.info(
                f"[save_student_scores] insert header class_id={class_id}, term={term}, exam_name={exam_name}"
            )
            
            # å¤„ç†excelæ–‡ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨JSONæ ¼å¼å­˜å‚¨ï¼ˆæ”¯æŒå¤šä¸ªæ–‡ä»¶ï¼ŒåŒ…å«descriptionä¸fieldsï¼‰
            final_excel_file_url = None
            if excel_files and isinstance(excel_files, list) and len(excel_files) > 0:
                url_dict = {}
                for ef in excel_files:
                    fn = ef.get('filename') or ef.get('name') or ef.get('file_name')
                    if not fn:
                        continue
                    url_dict[fn] = {
                        'url': ef.get('url', ''),
                        'description': ef.get('description', ''),
                        'fields': ef.get('fields', []) or []
                    }
                if url_dict:
                    final_excel_file_url = json.dumps(url_dict, ensure_ascii=False)
            elif excel_file_url:
                if excel_file_name:
                    # ä½¿ç”¨æ–°æ ¼å¼: {"æ–‡ä»¶å": {"url": "URL", "description": "è¯´æ˜", "fields": []}}
                    file_info = {
                        'url': excel_file_url,
                        'description': excel_file_description if excel_file_description else '',
                        'fields': []
                    }
                    url_dict = {excel_file_name: file_info}
                else:
                    # å¦‚æœæ²¡æœ‰æ–‡ä»¶åï¼Œä½¿ç”¨é»˜è®¤key
                    timestamp = int(time.time())
                    file_info = {
                        'url': excel_file_url,
                        'description': excel_file_description if excel_file_description else '',
                        'fields': []
                    }
                    url_dict = {f"excel_file_{timestamp}": file_info}
                final_excel_file_url = json.dumps(url_dict, ensure_ascii=False)
            
            if final_excel_file_url:
                try:
                    parsed_dict = json.loads(final_excel_file_url)
                    if isinstance(parsed_dict, dict):
                        for _, v in parsed_dict.items():
                            if isinstance(v, dict):
                                keep_fields_from_excel_urls.update(v.get('fields', []) or [])
                except Exception as e:
                    app_logger.warning(f"[save_student_scores] parse excel_file_url failed: {e}")
            
            insert_header_sql = (
                "INSERT INTO ta_student_score_header (class_id, exam_name, term, remark, excel_file_url, created_at) "
                "VALUES (%s, %s, %s, %s, %s, NOW())"
            )
            cursor.execute(insert_header_sql, (class_id, exam_name, term, remark, final_excel_file_url))
            score_header_id = cursor.lastrowid
            app_logger.info(f"[save_student_scores] header inserted score_header_id={score_header_id}")
        else:
            score_header_id = header_row['id']
            app_logger.info(f"[save_student_scores] header exists score_header_id={score_header_id}")
            # æ›´æ–°è¡¨å¤´ä¿¡æ¯ï¼ˆè‹¥å­˜åœ¨ï¼‰
            update_fields = []
            update_values = []
            # exam_name ä»…ç”¨äºå±•ç¤ºï¼šå¦‚æœå®¢æˆ·ç«¯ä¼ äº†æ–°å€¼ï¼Œåˆ™æ›´æ–°
            if provided_exam_name is not None:
                normalized_exam_name = str(provided_exam_name).strip()
                if normalized_exam_name:
                    update_fields.append("exam_name = %s")
                    update_values.append(normalized_exam_name)
                    app_logger.info(f"[save_student_scores] update header exam_name={normalized_exam_name}")
            if remark is not None:
                update_fields.append("remark = %s")
                update_values.append(remark)
            # æ›´æ–° excel_file_urlï¼ˆæ”¯æŒexcel_filesæ•°ç»„ï¼Œæˆ–å•ä¸ªexcel_file_urlï¼‰ï¼š
            # - åŒåæ–‡ä»¶åˆ™è¦†ç›–ï¼ˆurl/description/fieldsï¼‰
            # - ä¸åŒæ–‡ä»¶è¿½åŠ 
            # NOTE: è¿™é‡Œä¸å†æ‰“å° excel_file_url / SQL ç­‰è°ƒè¯•ä¿¡æ¯ï¼Œé¿å…æ—¥å¿—çˆ†ç‚¸
            
            # è®°å½•æœ¬æ¬¡ä¸Šä¼ æ¶‰åŠçš„æ–‡ä»¶å
            if excel_files and isinstance(excel_files, list) and len(excel_files) > 0:
                for ef in excel_files:
                    fn = ef.get('filename') or ef.get('name') or ef.get('file_name')
                    if fn:
                        uploaded_filenames.add(fn)
            elif excel_file_name:
                uploaded_filenames.add(excel_file_name)

            if (excel_files and isinstance(excel_files, list) and len(excel_files) > 0) or excel_file_url:
                # è·å–ç°æœ‰çš„excel_file_urlå€¼
                existing_excel_file_url = header_row.get('excel_file_url') if header_row else None
                print(f"[save_student_scores] ğŸ“‹ ç°æœ‰çš„excel_file_urlå€¼: {existing_excel_file_url}")
                app_logger.info(f"[save_student_scores] ğŸ“‹ ç°æœ‰çš„excel_file_urlå€¼: {existing_excel_file_url}")
                
                # è§£æç°æœ‰çš„URLåˆ—è¡¨ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰ï¼Œè½¬æ¢ä¸ºæ–°æ ¼å¼ï¼Œè¡¥é½fields
                url_dict = {}
                if existing_excel_file_url:
                    try:
                        existing_dict = json.loads(existing_excel_file_url)
                        if not isinstance(existing_dict, dict):
                            existing_dict = {}
                        # å½’ä¸€åŒ–ä¸ºæ–°æ ¼å¼
                        for filename, value in existing_dict.items():
                            if isinstance(value, dict):
                                url_dict[filename] = {
                                    'url': value.get('url', ''),
                                    'description': value.get('description', ''),
                                    'fields': value.get('fields', []) or []
                                }
                                if filename in uploaded_filenames:
                                    current_excel_old_fields.update(url_dict[filename]['fields'])
                                else:
                                    other_excels_fields.update(url_dict[filename]['fields'])
                            else:
                                url_dict[filename] = {
                                    'url': value,
                                    'description': '',
                                    'fields': []
                                }
                        print(f"[save_student_scores] âœ… æˆåŠŸè§£æç°æœ‰çš„URLå­—å…¸: {url_dict}")
                        app_logger.info(f"[save_student_scores] âœ… æˆåŠŸè§£æç°æœ‰çš„URLå­—å…¸: {url_dict}")
                    except (json.JSONDecodeError, TypeError):
                        # æ—§çš„å•URLæ ¼å¼
                        print(f"[save_student_scores] âš ï¸ ç°æœ‰å€¼ä¸æ˜¯JSONæ ¼å¼ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼")
                        app_logger.warning(f"[save_student_scores] âš ï¸ ç°æœ‰å€¼ä¸æ˜¯JSONæ ¼å¼ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼")
                        key_name = excel_file_name or 'excel_file'
                        url_dict[key_name] = {
                            'url': existing_excel_file_url,
                            'description': '',
                            'fields': []
                        }
                        if key_name in uploaded_filenames:
                            current_excel_old_fields.update(url_dict[key_name]['fields'])
                        else:
                            other_excels_fields.update(url_dict[key_name]['fields'])
                
                # æ›´æ–°æˆ–æ·»åŠ æ–°çš„æ–‡ä»¶ä¿¡æ¯
                if excel_files and isinstance(excel_files, list) and len(excel_files) > 0:
                    for ef in excel_files:
                        fn = ef.get('filename') or ef.get('name') or ef.get('file_name')
                        if not fn:
                            continue
                        url_dict[fn] = {
                            'url': ef.get('url', ''),
                            'description': ef.get('description', ''),
                            'fields': ef.get('fields', []) or []
                        }
                        if fn in uploaded_filenames:
                            current_excel_new_fields.update(url_dict[fn]['fields'])
                        else:
                            other_excels_fields.update(url_dict[fn]['fields'])
                        pass
                elif excel_file_url:
                    if excel_file_name:
                        url_dict[excel_file_name] = {
                            'url': excel_file_url,
                            'description': excel_file_description if excel_file_description else '',
                            'fields': []
                        }
                        current_excel_new_fields.update(url_dict[excel_file_name]['fields'])
                        pass
                    else:
                        timestamp = int(time.time())
                        default_key = f"excel_file_{timestamp}"
                        url_dict[default_key] = {
                            'url': excel_file_url,
                            'description': excel_file_description if excel_file_description else '',
                            'fields': []
                        }
                        current_excel_new_fields.update(url_dict[default_key]['fields'])
                        pass
                
                # å°†å­—å…¸è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²ä¿å­˜
                updated_excel_file_url = json.dumps(url_dict, ensure_ascii=False)
                
                update_fields.append("excel_file_url = %s")
                update_values.append(updated_excel_file_url)
                
                # ä»…ä¿ç•™å…¶ä»–excelçš„å­—æ®µï¼Œå½“å‰ä¸Šä¼ excelçš„å­—æ®µä¸åŠ å…¥ä¿ç•™é›†
                keep_fields_from_excel_urls = set(other_excels_fields)
            else:
                pass
            if update_fields:
                update_values.append(score_header_id)
                update_sql = f"UPDATE ta_student_score_header SET {', '.join(update_fields)}, updated_at = NOW() WHERE id = %s"
                cursor.execute(update_sql, tuple(update_values))
                app_logger.info(f"[save_student_scores] header updated score_header_id={score_header_id}, rowcount={cursor.rowcount}")
            else:
                pass
            # ä¸åˆ é™¤æ—§çš„æˆç»©æ˜ç»†å’Œå­—æ®µå®šä¹‰ï¼Œè€Œæ˜¯è¿½åŠ æ–°çš„æ•°æ®
            app_logger.info(f"[save_student_scores] append mode on existing header score_header_id={score_header_id}")

        # 2/3. ä¸å†æ‰“å° scores æ˜ç»†ä¸å­—æ®µåˆ—è¡¨ï¼ˆè¿‡å¤§ï¼‰ï¼›ä»…è®°å½•æ‘˜è¦
        app_logger.info(
            f"[save_student_scores] process fields/details score_header_id={score_header_id}, "
            f"operation_mode={operation_mode}, scores_count={len(scores)}"
        )
        
        # å¦‚æœæä¾›äº†fieldså‚æ•°ï¼Œä½¿ç”¨fieldsï¼›å¦åˆ™ä»scoresä¸­æå–ã€‚å¹¶åˆå¹¶excel_file_urlä¸­çš„å­—æ®µï¼Œé¿å…è¯¯åˆ å…¶ä»–excelå­—æ®µã€‚
        if fields and isinstance(fields, list) and len(fields) > 0:
            # ä½¿ç”¨æä¾›çš„å­—æ®µå®šä¹‰
            field_definitions = fields
            field_name_set = {f.get('field_name') for f in field_definitions if f.get('field_name')}
        else:
            # ä»scoresæ•°æ®ä¸­æå–æ‰€æœ‰å­—æ®µåï¼ˆé™¤äº†student_idå’Œstudent_nameï¼‰
            field_set = set()
            for score_item in scores:
                for key in score_item.keys():
                    if key not in ['student_id', 'student_name']:
                        field_set.add(key)
            
            # è½¬æ¢ä¸ºå­—æ®µå®šä¹‰æ ¼å¼
            field_definitions = []
            for idx, field_name in enumerate(sorted(list(field_set))):
                field_definitions.append({
                    'field_name': field_name,
                    'field_type': 'number',
                    'field_order': idx + 1,
                    'is_total': 1 if 'æ€»åˆ†' in field_name or 'total' in field_name.lower() else 0
                })
            field_name_set = field_set

        # åˆå¹¶excel_file_urlä¸­çš„â€œå…¶ä»–excelå­—æ®µâ€ï¼Œé˜²æ­¢æ›¿æ¢æ¨¡å¼è¯¯åˆ å®ƒä»¬ï¼›å½“å‰ä¸Šä¼ çš„excelå­—æ®µä¸åŠ å…¥ä¿ç•™é›†
        if keep_fields_from_excel_urls:
            field_name_set = set(field_name_set) if 'field_name_set' in locals() else set()
            field_name_set.update(keep_fields_from_excel_urls)
            # å°†ç¼ºå¤±åœ¨field_definitionsä¸­çš„â€œå…¶ä»–excelå­—æ®µâ€è¡¥å……åˆ°å®šä¹‰åˆ—è¡¨ï¼ˆä¿æŒåŸºç¡€å±æ€§ï¼Œé¡ºåºè¿½åŠ ï¼‰
            existing_def_names = {f.get('field_name') for f in field_definitions if f.get('field_name')}
            append_idx = len(field_definitions)
            for fname in sorted(list(keep_fields_from_excel_urls)):
                if fname not in existing_def_names:
                    append_idx += 1
                    field_definitions.append({
                        'field_name': fname,
                        'field_type': 'number',
                        'field_order': append_idx,
                        'is_total': 1 if 'æ€»åˆ†' in fname or 'total' in fname.lower() else 0
                    })
            pass

        # å½“å‰ä¸Šä¼ ä¸­æ¶‰åŠçš„å­—æ®µé›†åˆï¼ˆç”¨äºæ›¿æ¢æ¨¡å¼æ—¶ä¿ç•™å…¶ä»–excelçš„å­—æ®µï¼‰
        upload_field_set = set()
        for score_item in scores:
            for key in score_item.keys():
                if key not in ['student_id', 'student_name']:
                    upload_field_set.add(key)
        if not upload_field_set and fields:
            upload_field_set = {f.get('field_name') for f in fields if f.get('field_name')}
        
        # ç¡®å®šå½“å‰ä¸Šä¼ çš„Excelæ–‡ä»¶åï¼ˆç”¨äºå­—æ®µå®šä¹‰å’Œæˆç»©ä¿å­˜ï¼‰
        current_excel_filename = None
        if excel_files and isinstance(excel_files, list) and len(excel_files) > 0:
            # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„æ–‡ä»¶å
            current_excel_filename = excel_files[0].get('filename') or excel_files[0].get('name') or excel_files[0].get('file_name')
        elif excel_file_name:
            current_excel_filename = excel_file_name
        
        # å¦‚æœæ— æ³•ç¡®å®šæ–‡ä»¶åï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆé¿å… NOT NULL çº¦æŸé”™è¯¯ï¼‰
        if not current_excel_filename:
            current_excel_filename = f"excel_file_{int(time.time())}"
            app_logger.warning(f"[save_student_scores] âš ï¸ æ— æ³•ç¡®å®šExcelæ–‡ä»¶åï¼Œä½¿ç”¨é»˜è®¤å€¼: {current_excel_filename}")
        
        # 4. åœ¨æ›¿æ¢æ¨¡å¼ä¸‹ï¼Œåˆ é™¤ä¸åœ¨æ–°æ•°æ®ä¸­çš„å­—æ®µï¼ˆéœ€è¦æŒ‰ excel_filename å’Œ field_name ç»„åˆåˆ é™¤ï¼‰
        deleted_field_count = 0
        if operation_mode == 'replace' and field_name_set and current_excel_filename:
            # æŸ¥è¯¢å½“å‰Excelæ–‡ä»¶çš„æ‰€æœ‰ç°æœ‰å­—æ®µ
            cursor.execute(
                "SELECT field_name FROM ta_student_score_field WHERE score_header_id = %s AND excel_filename = %s",
                (score_header_id, current_excel_filename)
            )
            existing_fields = cursor.fetchall()
            existing_field_names = {f['field_name'] for f in existing_fields}
            
            # æ‰¾å‡ºéœ€è¦åˆ é™¤çš„å­—æ®µï¼ˆå­˜åœ¨äºå½“å‰Excelä½†ä¸åœ¨æ–°æ•°æ®ä¸­ï¼‰
            fields_to_delete = existing_field_names - field_name_set
            if fields_to_delete:
                delete_field_sql = "DELETE FROM ta_student_score_field WHERE score_header_id = %s AND field_name = %s AND excel_filename = %s"
                for field_name in fields_to_delete:
                    cursor.execute(delete_field_sql, (score_header_id, field_name, current_excel_filename))
                    deleted_field_count += 1
                    app_logger.info(f"[save_student_scores] åˆ é™¤å­—æ®µ: {field_name} (æ¥è‡ª {current_excel_filename})")
                app_logger.info(f"[save_student_scores] æ›¿æ¢æ¨¡å¼ä¸‹åˆ é™¤å­—æ®µå®Œæˆ - åˆ é™¤{deleted_field_count}ä¸ªå­—æ®µ")
        
        # 5. ä¿å­˜æˆ–æ›´æ–°å­—æ®µå®šä¹‰ï¼ˆæ·»åŠ  excel_filename å­—æ®µæ”¯æŒï¼‰
        if field_definitions:
            insert_field_sql = (
                "INSERT INTO ta_student_score_field "
                "(score_header_id, field_name, excel_filename, field_type, field_order, is_total) "
                "VALUES (%s, %s, %s, %s, %s, %s) "
                "ON DUPLICATE KEY UPDATE "
                "field_type = VALUES(field_type), "
                "field_order = VALUES(field_order), "
                "is_total = VALUES(is_total)"
            )
            new_field_count = 0
            updated_field_count = 0
            for field_def in field_definitions:
                field_name = field_def.get('field_name')
                if not field_name:
                    continue
                
                # æ£€æŸ¥å­—æ®µæ˜¯å¦å·²å­˜åœ¨ï¼ˆéœ€è¦åŒæ—¶åŒ¹é… field_name å’Œ excel_filenameï¼‰
                cursor.execute(
                    "SELECT id FROM ta_student_score_field WHERE score_header_id = %s AND field_name = %s AND excel_filename = %s",
                    (score_header_id, field_name, current_excel_filename)
                )
                existing_field = cursor.fetchone()
                
                field_type = field_def.get('field_type', 'number')
                field_order = field_def.get('field_order')
                is_total = field_def.get('is_total', 0)
                
                # å¦‚æœæ²¡æœ‰æä¾›field_orderï¼Œä½¿ç”¨é»˜è®¤å€¼
                if field_order is None:
                    if existing_field:
                        # ä¿æŒåŸæœ‰é¡ºåº
                        cursor.execute(
                            "SELECT field_order FROM ta_student_score_field WHERE score_header_id = %s AND field_name = %s AND excel_filename = %s",
                            (score_header_id, field_name, current_excel_filename)
                        )
                        order_result = cursor.fetchone()
                        field_order = order_result['field_order'] if order_result else 1
                    else:
                        # æ–°å­—æ®µï¼Œè¿½åŠ åˆ°æœ€åï¼ˆæŒ‰å½“å‰Excelæ–‡ä»¶çš„å­—æ®µé¡ºåºï¼‰
                        cursor.execute(
                            "SELECT MAX(field_order) as max_order FROM ta_student_score_field WHERE score_header_id = %s AND excel_filename = %s",
                            (score_header_id, current_excel_filename)
                        )
                        max_order_result = cursor.fetchone()
                        max_order = max_order_result['max_order'] if max_order_result and max_order_result['max_order'] is not None else 0
                        field_order = max_order + 1
                
                cursor.execute(insert_field_sql, (
                    score_header_id,
                    field_name,
                    current_excel_filename,
                    field_type,
                    field_order,
                    is_total
                ))
                
                if existing_field:
                    updated_field_count += 1
                    print(f"[save_student_scores] æ›´æ–°å­—æ®µ: {field_name} (é¡ºåº: {field_order})")
                    app_logger.info(f"[save_student_scores] æ›´æ–°å­—æ®µ: {field_name} (é¡ºåº: {field_order})")
                else:
                    new_field_count += 1
                    print(f"[save_student_scores] æ–°å¢å­—æ®µ: {field_name} (é¡ºåº: {field_order})")
                    app_logger.info(f"[save_student_scores] æ–°å¢å­—æ®µ: {field_name} (é¡ºåº: {field_order})")
            
            print(f"[save_student_scores] å­—æ®µå®šä¹‰ä¿å­˜å®Œæˆ - æ–°å¢{new_field_count}ä¸ªå­—æ®µï¼Œæ›´æ–°{updated_field_count}ä¸ªå­—æ®µï¼Œåˆ é™¤{deleted_field_count}ä¸ªå­—æ®µ")
            app_logger.info(f"[save_student_scores] å­—æ®µå®šä¹‰ä¿å­˜å®Œæˆ - æ–°å¢{new_field_count}ä¸ªå­—æ®µï¼Œæ›´æ–°{updated_field_count}ä¸ªå­—æ®µï¼Œåˆ é™¤{deleted_field_count}ä¸ªå­—æ®µ")

        # 6. åœ¨æ›¿æ¢æ¨¡å¼ä¸‹ï¼Œåˆ é™¤ä¸åœ¨æ–°æ•°æ®ä¸­çš„å­¦ç”Ÿ
        deleted_student_count = 0
        if operation_mode == 'replace':
            # æ”¶é›†æ–°æ•°æ®ä¸­çš„æ‰€æœ‰å­¦ç”Ÿæ ‡è¯†ï¼ˆstudent_name + student_idï¼‰
            new_student_keys = set()
            for score_item in scores:
                student_name = score_item.get('student_name', '').strip()
                student_id = score_item.get('student_id')
                if student_name:
                    # ä½¿ç”¨ (student_name, student_id) ä½œä¸ºå”¯ä¸€æ ‡è¯†
                    new_student_keys.add((student_name, student_id))
            
            # æŸ¥è¯¢æ‰€æœ‰ç°æœ‰å­¦ç”Ÿ
            cursor.execute(
                "SELECT id, student_name, student_id FROM ta_student_score_detail WHERE score_header_id = %s",
                (score_header_id,)
            )
            existing_students = cursor.fetchall()
            
            # æ‰¾å‡ºéœ€è¦åˆ é™¤çš„å­¦ç”Ÿï¼ˆå­˜åœ¨äºæ•°æ®åº“ä½†ä¸åœ¨æ–°æ•°æ®ä¸­ï¼‰
            students_to_delete = []
            for student in existing_students:
                student_name = student.get('student_name', '').strip()
                student_id = student.get('student_id')
                student_key = (student_name, student_id)
                if student_key not in new_student_keys:
                    students_to_delete.append(student['id'])
            
            if students_to_delete:
                delete_student_sql = "DELETE FROM ta_student_score_detail WHERE id = %s"
                for student_id_to_delete in students_to_delete:
                    cursor.execute(delete_student_sql, (student_id_to_delete,))
                    deleted_student_count += 1
                print(f"[save_student_scores] æ›¿æ¢æ¨¡å¼ä¸‹åˆ é™¤å­¦ç”Ÿå®Œæˆ - åˆ é™¤{deleted_student_count}ä¸ªå­¦ç”Ÿ")
                app_logger.info(f"[save_student_scores] æ›¿æ¢æ¨¡å¼ä¸‹åˆ é™¤å­¦ç”Ÿå®Œæˆ - åˆ é™¤{deleted_student_count}ä¸ªå­¦ç”Ÿ")
        
        # 7. æ‰¹é‡æ’å…¥æˆ–æ›´æ–°æˆç»©æ˜ç»†ï¼ˆä½¿ç”¨JSONæ ¼å¼å­˜å‚¨åŠ¨æ€å­—æ®µï¼‰
        print(f"[save_student_scores] å¼€å§‹æ’å…¥/æ›´æ–°æˆç»©æ˜ç»† - score_header_id={score_header_id}, operation_mode={operation_mode}, å¾…å¤„ç†æ•°é‡={len(scores)}")
        app_logger.info(f"[save_student_scores] å¼€å§‹æ’å…¥/æ›´æ–°æˆç»©æ˜ç»† - score_header_id={score_header_id}, operation_mode={operation_mode}, å¾…å¤„ç†æ•°é‡={len(scores)}")
        
        # ä½¿ç”¨ INSERT ... ON DUPLICATE KEY UPDATE æ¥æ”¯æŒæ’å…¥æˆ–æ›´æ–°
        # æ³¨æ„ï¼šéœ€è¦æ ¹æ®student_idå’Œstudent_nameæ¥åˆ¤æ–­æ˜¯å¦å·²å­˜åœ¨
        insert_detail_sql = (
            "INSERT INTO ta_student_score_detail "
            "(score_header_id, student_id, student_name, scores_json, comments_json, field_source_json, total_score) "
            "VALUES (%s, %s, %s, %s, %s, %s, %s) "
            "ON DUPLICATE KEY UPDATE "
            "scores_json = VALUES(scores_json), "
            "comments_json = VALUES(comments_json), "
            "field_source_json = VALUES(field_source_json), "
            "total_score = VALUES(total_score), "
            "updated_at = NOW()"
        )
        
        inserted_count = 0
        updated_count = 0
        skipped_count = 0
        
        for idx, score_item in enumerate(scores):
            student_id = score_item.get('student_id')
            student_name = score_item.get('student_name', '').strip()
            if not student_name:
                skipped_count += 1
                print(f"[save_student_scores] è·³è¿‡ç¬¬{idx+1}æ¡è®°å½•ï¼šç¼ºå°‘å­¦ç”Ÿå§“å - score_item={score_item}")
                app_logger.warning(f"[save_student_scores] è·³è¿‡ç¬¬{idx+1}æ¡è®°å½•ï¼šç¼ºå°‘å­¦ç”Ÿå§“å - score_item={score_item}")
                continue  # è·³è¿‡æ²¡æœ‰å§“åçš„è®°å½•
            
            # æ£€æŸ¥è¯¥å­¦ç”Ÿæ˜¯å¦å·²æœ‰æˆç»©è®°å½•
            check_sql = (
                "SELECT id, scores_json, field_source_json, comments_json FROM ta_student_score_detail "
                "WHERE score_header_id = %s AND student_name = %s "
                "AND (%s IS NULL OR student_id = %s) "
                "LIMIT 1"
            )
            cursor.execute(check_sql, (score_header_id, student_name, student_id, student_id))
            existing_record = cursor.fetchone()
            
            # æ„å»ºJSONå¯¹è±¡ï¼ˆä½¿ç”¨å¤åˆé”®åï¼šå­—æ®µå_Excelæ–‡ä»¶åï¼‰
            # è¿™æ ·å¯ä»¥æ”¯æŒåŒä¸€å­—æ®µåæ¥è‡ªä¸åŒExcelæ–‡ä»¶çš„æƒ…å†µ
            scores_json = {}
            comments_json = {}  # ä¿å­˜æ³¨é‡Šï¼ˆæ”¯æŒå¤åˆé”®åï¼‰
            field_source_json = {}  # è®°å½•å­—æ®µååˆ°Excelæ–‡ä»¶åçš„æ˜ å°„
            total_score = None
            for key, value in score_item.items():
                if key not in ['student_id', 'student_name']:
                    if value is not None:
                        # æ£€æŸ¥æ˜¯å¦ä¸ºæ³¨é‡Šå­—æ®µï¼ˆä»¥ _comment ç»“å°¾ï¼‰
                        if key.endswith('_comment'):
                            # è¿™æ˜¯æ³¨é‡Šå­—æ®µï¼Œæå–å­—æ®µåå¹¶ä¿å­˜åˆ° comments_json
                            field_name = key[:-8]  # å»æ‰ '_comment' åç¼€
                            comment_value = str(value).strip() if value else ''
                            if comment_value:
                                # ä½¿ç”¨å¤åˆé”®åä¿å­˜æ³¨é‡Šï¼ˆå­—æ®µå_Excelæ–‡ä»¶åï¼‰
                                comment_key = f"{field_name}_{current_excel_filename}" if current_excel_filename else field_name
                                comments_json[comment_key] = comment_value
                                # åŒæ—¶ä¸ºäº†å…¼å®¹æ€§ï¼Œä¹Ÿä¿å­˜ç®€å•å­—æ®µåï¼ˆå¦‚æœè¿˜æ²¡æœ‰çš„è¯ï¼‰
                                if field_name not in comments_json:
                                    comments_json[field_name] = comment_value
                        else:
                            # è¿™æ˜¯æˆç»©å­—æ®µï¼Œä¿å­˜åˆ° scores_json
                            # ä½¿ç”¨å¤åˆé”®åï¼ˆå­—æ®µå_Excelæ–‡ä»¶åï¼‰æ¥ä¿å­˜ï¼Œé¿å…åŒåå­—æ®µè¦†ç›–
                            composite_key = f"{key}_{current_excel_filename}" if current_excel_filename else key
                            
                            # å°è¯•è½¬æ¢ä¸ºæ•°å­—
                            try:
                                if isinstance(value, (int, float)):
                                    scores_json[composite_key] = float(value)
                                elif isinstance(value, str) and value.strip():
                                    # å°è¯•è§£æä¸ºæ•°å­—
                                    scores_json[composite_key] = float(value.strip())
                                else:
                                    scores_json[composite_key] = value
                            except (ValueError, TypeError):
                                scores_json[composite_key] = value
                            
                            # è®°å½•å­—æ®µæ¥æºæ˜ å°„ï¼ˆå¦‚æœåŒä¸€å­—æ®µåæ¥è‡ªå¤šä¸ªExcelï¼Œä½¿ç”¨æ•°ç»„ï¼‰
                            if key in field_source_json:
                                # å¦‚æœå·²æœ‰è®°å½•ï¼Œè½¬æ¢ä¸ºæ•°ç»„
                                existing_source = field_source_json[key]
                                if isinstance(existing_source, str):
                                    field_source_json[key] = [existing_source, current_excel_filename] if current_excel_filename else existing_source
                                elif isinstance(existing_source, list):
                                    if current_excel_filename and current_excel_filename not in existing_source:
                                        existing_source.append(current_excel_filename)
                            else:
                                # é¦–æ¬¡è®°å½•
                                field_source_json[key] = current_excel_filename if current_excel_filename else key
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºæ€»åˆ†å­—æ®µ
                        if ('æ€»åˆ†' in key or 'total' in key.lower()) and value is not None:
                            try:
                                # å¦‚æœæœ‰å¤šä¸ª"æ€»åˆ†"å­—æ®µï¼Œå–æœ€åä¸€ä¸ªï¼ˆæˆ–è€…å¯ä»¥æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´ï¼‰
                                total_score = float(value)
                            except (ValueError, TypeError):
                                pass
            
            # åœ¨è¿½åŠ æ¨¡å¼ä¸‹ï¼Œå¦‚æœè®°å½•å·²å­˜åœ¨ï¼Œåˆå¹¶JSONæ•°æ®ï¼ˆä¿ç•™æ—§å­—æ®µï¼Œæ·»åŠ æ–°å­—æ®µï¼‰
            # åœ¨æ›¿æ¢æ¨¡å¼ä¸‹ï¼Œä»…æ›¿æ¢æœ¬æ¬¡ä¸Šä¼ æ¶‰åŠçš„å­—æ®µï¼Œä¿ç•™å…¶ä»–excelçš„å­—æ®µ
            existing_field_source_json = {}
            existing_comments_json = {}
            if existing_record and existing_record.get('field_source_json'):
                try:
                    existing_field_source_json = json.loads(existing_record['field_source_json']) if isinstance(existing_record['field_source_json'], str) else existing_record['field_source_json']
                except (json.JSONDecodeError, TypeError):
                    existing_field_source_json = {}
            
            if existing_record and existing_record.get('comments_json'):
                try:
                    existing_comments_json = json.loads(existing_record['comments_json']) if isinstance(existing_record['comments_json'], str) else existing_record['comments_json']
                except (json.JSONDecodeError, TypeError):
                    existing_comments_json = {}
            
            if operation_mode == 'append' and existing_record and existing_record.get('scores_json'):
                try:
                    existing_json = json.loads(existing_record['scores_json']) if isinstance(existing_record['scores_json'], str) else existing_record['scores_json']
                    # åˆå¹¶æ—¶ï¼Œå¤åˆé”®åä¸ä¼šå†²çªï¼ˆå› ä¸ºåŒ…å«Excelæ–‡ä»¶åï¼‰
                    merged_json = {**existing_json, **scores_json}
                    scores_json = merged_json
                    # åˆå¹¶å­—æ®µæ¥æºæ˜ å°„
                    field_source_json = {**existing_field_source_json, **field_source_json}
                    # åˆå¹¶æ³¨é‡Šï¼ˆå¤åˆé”®åä¸ä¼šå†²çªï¼‰
                    comments_json = {**existing_comments_json, **comments_json}
                    print(f"[save_student_scores] åˆå¹¶å·²æœ‰æˆç»©æ•°æ® - student_name={student_name}, æ—§å­—æ®µæ•°={len(existing_json)}, æ–°å­—æ®µæ•°={len(scores_json)}")
                    app_logger.info(f"[save_student_scores] åˆå¹¶å·²æœ‰æˆç»©æ•°æ® - student_name={student_name}")
                except (json.JSONDecodeError, TypeError) as e:
                    print(f"[save_student_scores] è§£æå·²æœ‰JSONå¤±è´¥ï¼Œä½¿ç”¨æ–°æ•°æ® - student_name={student_name}, error={e}")
                    app_logger.warning(f"[save_student_scores] è§£æå·²æœ‰JSONå¤±è´¥ï¼Œä½¿ç”¨æ–°æ•°æ® - student_name={student_name}, error={e}")
            elif operation_mode == 'replace' and existing_record and existing_record.get('scores_json'):
                try:
                    existing_json = json.loads(existing_record['scores_json']) if isinstance(existing_record['scores_json'], str) else existing_record['scores_json']
                    # æ›¿æ¢æ¨¡å¼ä¸‹ï¼Œä»…åˆ é™¤å½“å‰Excelæ–‡ä»¶çš„å­—æ®µï¼Œä¿ç•™å…¶ä»–Excelçš„å­—æ®µ
                    # ä¿ç•™ä¸ä»¥å½“å‰Excelæ–‡ä»¶åç»“å°¾çš„å­—æ®µï¼ˆå³å…¶ä»–Excelçš„å­—æ®µï¼‰
                    preserved = {k: v for k, v in existing_json.items() if not k.endswith(f"_{current_excel_filename}")}
                    scores_json = {**preserved, **scores_json}
                    # åŒæ ·å¤„ç†å­—æ®µæ¥æºæ˜ å°„ï¼šåˆ é™¤å½“å‰Excelçš„å­—æ®µæ˜ å°„ï¼Œä¿ç•™å…¶ä»–çš„
                    preserved_sources = {k: v for k, v in existing_field_source_json.items() 
                                        if (isinstance(v, str) and v != current_excel_filename) or
                                           (isinstance(v, list) and current_excel_filename not in v)}
                    field_source_json = {**preserved_sources, **field_source_json}
                    # åŒæ ·å¤„ç†æ³¨é‡Šï¼šåˆ é™¤å½“å‰Excelçš„æ³¨é‡Šï¼Œä¿ç•™å…¶ä»–çš„
                    preserved_comments = {k: v for k, v in existing_comments_json.items() 
                                         if not k.endswith(f"_{current_excel_filename}")}
                    comments_json = {**preserved_comments, **comments_json}
                    app_logger.info(f"[save_student_scores] æ›¿æ¢æ¨¡å¼ä¿ç•™å…¶ä»–excelå­—æ®µ - student_name={student_name}")
                except (json.JSONDecodeError, TypeError) as e:
                    app_logger.warning(f"[save_student_scores] æ›¿æ¢æ¨¡å¼è§£æå·²æœ‰JSONå¤±è´¥ï¼Œä½¿ç”¨æ–°æ•°æ® - student_name={student_name}, error={e}")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ€»åˆ†å­—æ®µï¼Œè‡ªåŠ¨è®¡ç®—æ€»åˆ†ï¼ˆæ‰€æœ‰æ•°å­—å­—æ®µçš„å’Œï¼‰
            if total_score is None:
                total_score = 0.0
                for key, value in scores_json.items():
                    if isinstance(value, (int, float)):
                        total_score += float(value)
                if total_score == 0.0:
                    total_score = None  # å¦‚æœæ‰€æœ‰å€¼éƒ½æ˜¯0æˆ–æ²¡æœ‰å€¼ï¼Œè®¾ä¸ºNone
            
            # å°†scores_jsonã€comments_jsonå’Œfield_source_jsonè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
            scores_json_str = json.dumps(scores_json, ensure_ascii=False)
            comments_json_str = json.dumps(comments_json, ensure_ascii=False) if comments_json else None
            field_source_json_str = json.dumps(field_source_json, ensure_ascii=False) if field_source_json else None
            
            is_update = existing_record is not None
            action = "æ›´æ–°" if is_update else "æ’å…¥"
            # é€æ¡æˆç»©æ˜ç»†ä¸å†æ‰“å° JSONï¼ˆè¿‡å¤§ï¼‰ï¼›åªåœ¨å¤±è´¥æ—¶è®°å½•
            
            try:
                # å¦‚æœè®°å½•å·²å­˜åœ¨ï¼Œä½¿ç”¨UPDATEè¯­å¥
                if existing_record:
                    update_detail_sql = (
                        "UPDATE ta_student_score_detail "
                        "SET scores_json = %s, comments_json = %s, field_source_json = %s, total_score = %s, updated_at = NOW() "
                        "WHERE id = %s"
                    )
                    cursor.execute(update_detail_sql, (
                        scores_json_str,
                        comments_json_str,
                        field_source_json_str,
                        total_score,
                        existing_record['id']
                    ))
                    updated_count += 1
                else:
                    # æ–°è®°å½•ï¼Œä½¿ç”¨INSERT
                    cursor.execute(insert_detail_sql, (
                        score_header_id,
                        student_id,
                        student_name,
                        scores_json_str,
                        comments_json_str,
                        field_source_json_str,
                        total_score
                    ))
                    inserted_count += 1
            except Exception as insert_error:
                app_logger.error(f"[save_student_scores] ç¬¬{idx+1}æ¡æˆç»©{action}å¤±è´¥ - student_name={student_name}, error={insert_error}", exc_info=True)
                raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©å¤–å±‚æ•è·

        app_logger.info(f"[save_student_scores] æˆç»©æ˜ç»†å¤„ç†å®Œæˆ - æ’å…¥={inserted_count}, æ›´æ–°={updated_count}, è·³è¿‡={skipped_count}, æ€»è®¡={len(scores)}")
        
        connection.commit()
        total_processed = inserted_count + updated_count
        app_logger.info(f"[save_student_scores] äº‹åŠ¡æäº¤æˆåŠŸ - score_header_id={score_header_id}, æ’å…¥={inserted_count}, æ›´æ–°={updated_count}, åˆ é™¤å­—æ®µ={deleted_field_count}, åˆ é™¤å­¦ç”Ÿ={deleted_student_count}, æ€»è®¡={total_processed}")
        return { 
            'success': True, 
            'score_header_id': score_header_id, 
            'inserted_count': inserted_count, 
            'updated_count': updated_count,
            'deleted_field_count': deleted_field_count,
            'deleted_student_count': deleted_student_count,
            'message': 'ä¿å­˜æˆåŠŸ' 
        }
    except mysql.connector.Error as e:
        if connection and connection.is_connected():
            app_logger.error(f"[save_student_scores] æ•°æ®åº“é”™è¯¯ï¼Œå›æ»šäº‹åŠ¡ - error={e}")
            connection.rollback()
        else:
            app_logger.error(f"[save_student_scores] æ•°æ®åº“é”™è¯¯ï¼Œè¿æ¥å·²æ–­å¼€ - error={e}")
        app_logger.error(f"Database error during save_student_scores: {e}", exc_info=True)
        return { 'success': False, 'score_header_id': None, 'inserted_count': 0, 'message': f'æ•°æ®åº“é”™è¯¯: {e}' }
    except Exception as e:
        if connection and connection.is_connected():
            app_logger.error(f"[save_student_scores] æœªçŸ¥é”™è¯¯ï¼Œå›æ»šäº‹åŠ¡ - error={e}")
            connection.rollback()
        else:
            app_logger.error(f"[save_student_scores] æœªçŸ¥é”™è¯¯ï¼Œè¿æ¥å·²æ–­å¼€ - error={e}")
        app_logger.error(f"Unexpected error during save_student_scores: {e}", exc_info=True)
        return { 'success': False, 'score_header_id': None, 'inserted_count': 0, 'message': f'æœªçŸ¥é”™è¯¯: {e}' }
    finally:
        if connection and connection.is_connected():
            connection.close()
            app_logger.info("Database connection closed after saving student scores.")


def save_group_scores(
    class_id: str,
    exam_name: Optional[str] = None,
    term: Optional[str] = None,
    remark: Optional[str] = None,
    scores: List[Dict] = None,
    excel_file_url: Optional[str] = None,
    excel_file_name: Optional[str] = None,
    excel_file_description: Optional[str] = None,
    operation_mode: str = 'append',
    fields: List[Dict] = None,
    excel_files: List[Dict] = None
) -> Dict[str, object]:
    """
    ä¿å­˜å°ç»„æˆç»©è¡¨ï¼ˆæ”¯æŒåŠ¨æ€å­—æ®µï¼Œä½¿ç”¨JSONå­˜å‚¨ï¼‰
    å‚æ•°è¯´æ˜ï¼š
    - class_id: ç­çº§IDï¼ˆå¿…éœ€ï¼‰
    - exam_name: è€ƒè¯•/è¡¨åç§°ï¼ˆå¯é€‰ï¼Œä»…å±•ç¤ºå­—æ®µï¼›ä¸å†ä½œä¸ºå®šä½æ¡ä»¶ï¼‰
    - term: å­¦æœŸï¼ˆå¯é€‰ï¼Œå¦‚ '2025-2026-1'ï¼‰
    - remark: å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰
    - excel_file_url: Excelæ–‡ä»¶åœ¨OSSçš„URLï¼ˆå¯é€‰ï¼‰
    - excel_file_name: Excelæ–‡ä»¶åï¼ˆå¯é€‰ï¼Œç”¨äºç®¡ç†å¤šä¸ªæ–‡ä»¶ï¼‰
    - excel_file_description: Excelæ–‡ä»¶è¯´æ˜ï¼ˆå¯é€‰ï¼‰
    - operation_mode: æ“ä½œæ¨¡å¼ï¼Œ'append'ï¼ˆè¿½åŠ ï¼Œé»˜è®¤ï¼‰æˆ– 'replace'ï¼ˆæ›¿æ¢ï¼‰
    - fields: å­—æ®µå®šä¹‰åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
      {
        'field_name': str,      # å­—æ®µåç§°ï¼ˆå¿…éœ€ï¼‰
        'field_type': str,       # å­—æ®µç±»å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤'number'ï¼‰
        'field_order': int,      # å­—æ®µé¡ºåºï¼ˆå¯é€‰ï¼‰
        'is_total': int          # æ˜¯å¦ä¸ºæ€»åˆ†å­—æ®µï¼ˆå¯é€‰ï¼Œ0æˆ–1ï¼‰
      }
    - excel_files: Excelæ–‡ä»¶åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
      {
        'filename': str,         # æ–‡ä»¶åï¼ˆå¿…éœ€ï¼‰
        'url': str,              # æ–‡ä»¶URLï¼ˆå¿…éœ€ï¼‰
        'description': str,       # æ–‡ä»¶è¯´æ˜ï¼ˆå¯é€‰ï¼‰
        'fields': [str]          # è¯¥æ–‡ä»¶å¯¹åº”çš„å­—æ®µåˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
      }
    - scores: æˆç»©æ˜ç»†åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
      {
        'group_name': str,       # å°ç»„åç§°/ç¼–å·ï¼ˆå¿…éœ€ï¼Œå¦‚"1"æˆ–"1ç»„"ï¼‰
        'student_id': str,       # å­¦å·ï¼ˆå¯é€‰ï¼‰
        'student_name': str,     # å§“åï¼ˆå¿…éœ€ï¼‰
        'è¯­æ–‡': int,              # å„ç§‘æˆç»©ï¼ˆåŠ¨æ€å­—æ®µï¼‰
        'æ•°å­¦': int,
        'è‹±è¯­': int,
        'æ€»åˆ†': float,            # ä¸ªäººæ€»åˆ†ï¼ˆå¯é€‰ï¼Œå¯è‡ªåŠ¨è®¡ç®—ï¼‰
        'group_total_score': float  # å°ç»„æ€»åˆ†ï¼ˆå¯é€‰ï¼Œå¯è‡ªåŠ¨è®¡ç®—ï¼‰
      }
    
    è¿”å›ï¼š
    - { success, score_header_id, inserted_count, updated_count, deleted_count, message }
    """
    if not class_id:
        return { 'success': False, 'score_header_id': None, 'inserted_count': 0, 'message': 'ç¼ºå°‘å¿…è¦å‚æ•° class_id' }

    exam_name_norm = str(exam_name).strip() if exam_name is not None and str(exam_name).strip() else None
    
    # éªŒè¯operation_mode
    if operation_mode not in ['append', 'replace']:
        operation_mode = 'append'  # é»˜è®¤ä½¿ç”¨è¿½åŠ æ¨¡å¼
    
    # åœ¨æ›¿æ¢æ¨¡å¼ä¸‹ï¼Œscoreså¯ä»¥ä¸ºç©ºï¼ˆç”¨äºåˆ é™¤æ‰€æœ‰æ•°æ®ï¼‰
    if operation_mode == 'replace' and (not scores or not isinstance(scores, list)):
        scores = []
    elif operation_mode == 'append' and (not scores or not isinstance(scores, list)):
        return { 'success': False, 'score_header_id': None, 'inserted_count': 0, 'message': 'æˆç»©æ˜ç»†åˆ—è¡¨ä¸èƒ½ä¸ºç©º' }

    print(f"[save_group_scores] å¼€å§‹ä¿å­˜å°ç»„æˆç»© - class_id={class_id}, exam_name={exam_name_norm}, term={term}, operation_mode={operation_mode}, scoresæ•°é‡={len(scores) if scores else 0}")
    app_logger.info(f"[save_group_scores] å¼€å§‹ä¿å­˜å°ç»„æˆç»© - class_id={class_id}, exam_name={exam_name_norm}, term={term}, operation_mode={operation_mode}, scoresæ•°é‡={len(scores) if scores else 0}")
    
    connection = get_db_connection()
    if connection is None:
        error_msg = "Save group scores failed: Database connection error."
        print(f"[save_group_scores] é”™è¯¯: {error_msg}")
        app_logger.error(error_msg)
        return { 'success': False, 'score_header_id': None, 'inserted_count': 0, 'message': 'æ•°æ®åº“è¿æ¥å¤±è´¥' }

    print(f"[save_group_scores] æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œå¼€å§‹äº‹åŠ¡")
    app_logger.info(f"[save_group_scores] æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œå¼€å§‹äº‹åŠ¡")
    try:
        connection.start_transaction()
        cursor = connection.cursor(dictionary=True)

        # 1. æ’å…¥æˆ–è·å–å°ç»„æˆç»©è¡¨å¤´
        # çº¦å®šï¼šclass_id + term å”¯ä¸€å®šä½ä¸€å¼ å°ç»„æˆç»©è¡¨ï¼›exam_name ä»…å±•ç¤ºå­—æ®µï¼Œä¸å‚ä¸å®šä½
        print(f"[save_group_scores] æŸ¥è¯¢å°ç»„æˆç»©è¡¨å¤´ - class_id={class_id}, term={term}ï¼ˆå¿½ç•¥exam_nameå®šä½ï¼š{exam_name_norm}ï¼‰")
        app_logger.info(f"[save_group_scores] æŸ¥è¯¢å°ç»„æˆç»©è¡¨å¤´ - class_id={class_id}, term={term}ï¼ˆå¿½ç•¥exam_nameå®šä½ï¼š{exam_name_norm}ï¼‰")
        cursor.execute(
            "SELECT id, excel_file_url, exam_name "
            "FROM ta_group_score_header "
            "WHERE class_id = %s AND ((%s IS NULL AND term IS NULL) OR term = %s) "
            "ORDER BY created_at DESC LIMIT 1",
            (class_id, term, term)
        )
        header_row = cursor.fetchone()
        print(f"[save_group_scores] æŸ¥è¯¢å°ç»„æˆç»©è¡¨å¤´ç»“æœ: {header_row}")
        app_logger.info(f"[save_group_scores] æŸ¥è¯¢å°ç»„æˆç»©è¡¨å¤´ç»“æœ: {header_row}")

        # æ”¶é›†éœ€è¦ä¿ç•™çš„å­—æ®µï¼ˆæ¥è‡ªå…¶ä»–Excelæ–‡ä»¶ï¼‰
        keep_fields_from_excel_urls = set()
        current_excel_filenames = set()
        if excel_files and isinstance(excel_files, list):
            for ef in excel_files:
                fn = ef.get('filename') or ef.get('name') or ef.get('file_name')
                if fn:
                    current_excel_filenames.add(fn)
        elif excel_file_name:
            current_excel_filenames.add(excel_file_name)

        if header_row is None:
            # æ’å…¥æ–°è¡¨å¤´
            print(f"[save_group_scores] ========== æ’å…¥æ–°å°ç»„æˆç»©è¡¨å¤´ ==========")
            app_logger.info(f"[save_group_scores] ========== æ’å…¥æ–°å°ç»„æˆç»©è¡¨å¤´ ==========")

            # exam_name å…è®¸ä¸ä¼ ï¼Œä½†åˆ—ä¸º NOT NULLï¼Œè¿™é‡Œç»™é»˜è®¤å±•ç¤ºå
            exam_name_to_store = exam_name_norm or "å°ç»„æˆç»©"
            
            # å¤„ç†Excelæ–‡ä»¶URLï¼ˆç±»ä¼¼å­¦ç”Ÿæˆç»©æ¥å£ï¼‰
            final_excel_file_url = None
            if excel_files and isinstance(excel_files, list) and len(excel_files) > 0:
                url_dict = {}
                for ef in excel_files:
                    fn = ef.get('filename') or ef.get('name') or ef.get('file_name')
                    if not fn:
                        continue
                    # å¦‚æœURLä¸ºç©ºä½†excel_file_urlæœ‰å€¼ï¼Œä½¿ç”¨excel_file_url
                    file_url = ef.get('url', '')
                    if not file_url and excel_file_url:
                        file_url = excel_file_url
                        print(f"[save_group_scores] âœ… åˆ›å»ºè¡¨å¤´æ—¶ä½¿ç”¨excel_file_urlå¡«å……excel_filesä¸­çš„URL: {fn} -> {file_url}")
                        app_logger.info(f"[save_group_scores] âœ… åˆ›å»ºè¡¨å¤´æ—¶ä½¿ç”¨excel_file_urlå¡«å……excel_filesä¸­çš„URL: {fn} -> {file_url}")
                    url_dict[fn] = {
                        'url': file_url,
                        'description': ef.get('description', ''),
                        'fields': ef.get('fields', []) or []
                    }
                final_excel_file_url = json.dumps(url_dict, ensure_ascii=False)
            elif excel_file_url:
                if excel_file_name:
                    file_info = {
                        'url': excel_file_url,
                        'description': excel_file_description if excel_file_description else '',
                        'fields': []
                    }
                    url_dict = {excel_file_name: file_info}
                else:
                    timestamp = int(time.time())
                    file_info = {
                        'url': excel_file_url,
                        'description': excel_file_description if excel_file_description else '',
                        'fields': []
                    }
                    url_dict = {f"excel_file_{timestamp}": file_info}
                final_excel_file_url = json.dumps(url_dict, ensure_ascii=False)
            
            insert_header_sql = (
                "INSERT INTO ta_group_score_header (class_id, exam_name, term, remark, excel_file_url, created_at) "
                "VALUES (%s, %s, %s, %s, %s, NOW())"
            )
            cursor.execute(insert_header_sql, (class_id, exam_name_to_store, term, remark, final_excel_file_url))
            score_header_id = cursor.lastrowid
            print(f"[save_group_scores] âœ… æ’å…¥å°ç»„æˆç»©è¡¨å¤´æˆåŠŸ - score_header_id={score_header_id}")
            app_logger.info(f"[save_group_scores] âœ… æ’å…¥å°ç»„æˆç»©è¡¨å¤´æˆåŠŸ - score_header_id={score_header_id}")
        else:
            score_header_id = header_row['id']
            print(f"[save_group_scores] ========== å°ç»„æˆç»©è¡¨å¤´å·²å­˜åœ¨ï¼Œå‡†å¤‡æ›´æ–° ==========")
            app_logger.info(f"[save_group_scores] ========== å°ç»„æˆç»©è¡¨å¤´å·²å­˜åœ¨ï¼Œå‡†å¤‡æ›´æ–° ==========")
            
            # æ›´æ–°è¡¨å¤´ä¿¡æ¯ï¼ˆç±»ä¼¼å­¦ç”Ÿæˆç»©æ¥å£çš„Excelæ–‡ä»¶å¤„ç†é€»è¾‘ï¼‰
            update_fields = []
            update_values = []
            # exam_name ä¸å†å‚ä¸å®šä½ï¼šå¦‚æœå®¢æˆ·ç«¯ä¼ äº†ï¼Œåˆ™ä½œä¸ºå±•ç¤ºå­—æ®µæ›´æ–°
            if exam_name_norm is not None:
                update_fields.append("exam_name = %s")
                update_values.append(exam_name_norm)
            if remark is not None:
                update_fields.append("remark = %s")
                update_values.append(remark)
            
            # å¤„ç†Excelæ–‡ä»¶URLæ›´æ–°ï¼ˆå‚è€ƒå­¦ç”Ÿæˆç»©æ¥å£çš„å®ç°ï¼‰
            if (excel_files and isinstance(excel_files, list) and len(excel_files) > 0) or excel_file_url:
                existing_excel_file_url = header_row.get('excel_file_url')
                url_dict = {}
                if existing_excel_file_url:
                    try:
                        existing_dict = json.loads(existing_excel_file_url)
                        if isinstance(existing_dict, dict):
                            for filename, value in existing_dict.items():
                                if isinstance(value, dict):
                                    url_dict[filename] = {
                                        'url': value.get('url', ''),
                                        'description': value.get('description', ''),
                                        'fields': value.get('fields', []) or []
                                    }
                                    # å¦‚æœæ˜¯å…¶ä»–Excelæ–‡ä»¶çš„å­—æ®µï¼Œéœ€è¦ä¿ç•™
                                    if filename not in current_excel_filenames:
                                        keep_fields_from_excel_urls.update(url_dict[filename]['fields'])
                                else:
                                    url_dict[filename] = {
                                        'url': value,
                                        'description': '',
                                        'fields': []
                                    }
                                    if filename not in current_excel_filenames:
                                        keep_fields_from_excel_urls.update(url_dict[filename]['fields'])
                    except (json.JSONDecodeError, TypeError):
                        pass
                
                # æ›´æ–°æˆ–æ·»åŠ æ–°çš„æ–‡ä»¶ä¿¡æ¯
                if excel_files and isinstance(excel_files, list) and len(excel_files) > 0:
                    for ef in excel_files:
                        fn = ef.get('filename') or ef.get('name') or ef.get('file_name')
                        if not fn:
                            continue
                        # å¦‚æœURLä¸ºç©ºä½†excel_file_urlæœ‰å€¼ï¼Œä½¿ç”¨excel_file_url
                        file_url = ef.get('url', '')
                        if not file_url and excel_file_url:
                            file_url = excel_file_url
                            print(f"[save_group_scores] âœ… ä½¿ç”¨excel_file_urlå¡«å……excel_filesä¸­çš„URL: {fn} -> {file_url}")
                            app_logger.info(f"[save_group_scores] âœ… ä½¿ç”¨excel_file_urlå¡«å……excel_filesä¸­çš„URL: {fn} -> {file_url}")
                        url_dict[fn] = {
                            'url': file_url,
                            'description': ef.get('description', ''),
                            'fields': ef.get('fields', []) or []
                        }
                elif excel_file_url:
                    if excel_file_name:
                        url_dict[excel_file_name] = {
                            'url': excel_file_url,
                            'description': excel_file_description if excel_file_description else '',
                            'fields': []
                        }
                    else:
                        timestamp = int(time.time())
                        default_key = f"excel_file_{timestamp}"
                        url_dict[default_key] = {
                            'url': excel_file_url,
                            'description': excel_file_description if excel_file_description else '',
                            'fields': []
                        }
                
                updated_excel_file_url = json.dumps(url_dict, ensure_ascii=False)
                update_fields.append("excel_file_url = %s")
                update_values.append(updated_excel_file_url)
            
            if update_fields:
                update_values.append(score_header_id)
                update_sql = f"UPDATE ta_group_score_header SET {', '.join(update_fields)}, updated_at = NOW() WHERE id = %s"
                cursor.execute(update_sql, tuple(update_values))
                print(f"[save_group_scores] âœ… UPDATEæ‰§è¡ŒæˆåŠŸï¼Œå½±å“è¡Œæ•°: {cursor.rowcount}")
                app_logger.info(f"[save_group_scores] âœ… UPDATEæ‰§è¡ŒæˆåŠŸï¼Œå½±å“è¡Œæ•°: {cursor.rowcount}")

        # 2. å¤„ç†å­—æ®µå®šä¹‰ï¼ˆç±»ä¼¼å­¦ç”Ÿæˆç»©æ¥å£ï¼Œä½†å°ç»„æˆç»©ä¸éœ€è¦å­—æ®µå®šä¹‰è¡¨ï¼Œç›´æ¥ä½¿ç”¨scores_jsonï¼‰
        print(f"[save_group_scores] ========== æ”¶åˆ°scoresæ•°æ® ==========")
        print(f"[save_group_scores] scoresæ•°é‡: {len(scores)}")
        app_logger.info(f"[save_group_scores] æ”¶åˆ°scoresæ•°æ®: {json.dumps(scores, ensure_ascii=False, indent=2) if scores else '[]'}")
        
        # 3. åœ¨æ›¿æ¢æ¨¡å¼ä¸‹ï¼Œåˆ é™¤ä¸åœ¨æ–°æ•°æ®ä¸­çš„å­¦ç”Ÿ
        deleted_student_count = 0
        if operation_mode == 'replace':
            new_student_keys = set()
            for score_item in scores:
                student_name = score_item.get('student_name', '').strip()
                student_id = score_item.get('student_id')
                if student_name:
                    new_student_keys.add((student_name, student_id))
            
            cursor.execute(
                "SELECT id, student_name, student_id FROM ta_group_score_detail WHERE score_header_id = %s",
                (score_header_id,)
            )
            existing_students = cursor.fetchall()
            
            students_to_delete = []
            for student in existing_students:
                student_name = student.get('student_name', '').strip()
                student_id = student.get('student_id')
                student_key = (student_name, student_id)
                if student_key not in new_student_keys:
                    students_to_delete.append(student['id'])
            
            if students_to_delete:
                delete_student_sql = "DELETE FROM ta_group_score_detail WHERE id = %s"
                for student_id_to_delete in students_to_delete:
                    cursor.execute(delete_student_sql, (student_id_to_delete,))
                    deleted_student_count += 1
                print(f"[save_group_scores] æ›¿æ¢æ¨¡å¼ä¸‹åˆ é™¤å­¦ç”Ÿå®Œæˆ - åˆ é™¤{deleted_student_count}ä¸ªå­¦ç”Ÿ")
                app_logger.info(f"[save_group_scores] æ›¿æ¢æ¨¡å¼ä¸‹åˆ é™¤å­¦ç”Ÿå®Œæˆ - åˆ é™¤{deleted_student_count}ä¸ªå­¦ç”Ÿ")
        
        # 4. è®¡ç®—å°ç»„æ€»åˆ†ï¼ˆæŒ‰å°ç»„åˆ†ç»„è®¡ç®—ï¼‰
        group_totals = {}  # {group_name: total_score}
        if scores:
            for score_item in scores:
                group_name = score_item.get('group_name', '').strip()
                if not group_name:
                    continue
                
                # è®¡ç®—ä¸ªäººæ€»åˆ†
                total_score = score_item.get('æ€»åˆ†') or score_item.get('total_score')
                if total_score is None:
                    # è‡ªåŠ¨è®¡ç®—æ€»åˆ†ï¼ˆæ‰€æœ‰æ•°å­—å­—æ®µçš„å’Œï¼‰
                    total_score = 0.0
                    for key, value in score_item.items():
                        if key not in ['group_name', 'student_id', 'student_name', 'group_total_score', 'æ€»åˆ†', 'total_score']:
                            if isinstance(value, (int, float)):
                                total_score += float(value)
                    if total_score == 0.0:
                        total_score = None
                
                # ç´¯åŠ å°ç»„æ€»åˆ†
                if total_score is not None:
                    if group_name not in group_totals:
                        group_totals[group_name] = 0.0
                    group_totals[group_name] += float(total_score)
        
        # 5. æ‰¹é‡æ’å…¥æˆ–æ›´æ–°æˆç»©æ˜ç»†
        print(f"[save_group_scores] å¼€å§‹æ’å…¥/æ›´æ–°æˆç»©æ˜ç»† - score_header_id={score_header_id}, operation_mode={operation_mode}, å¾…å¤„ç†æ•°é‡={len(scores)}")
        app_logger.info(f"[save_group_scores] å¼€å§‹æ’å…¥/æ›´æ–°æˆç»©æ˜ç»† - score_header_id={score_header_id}, operation_mode={operation_mode}, å¾…å¤„ç†æ•°é‡={len(scores)}")
        
        insert_detail_sql = (
            "INSERT INTO ta_group_score_detail "
            "(score_header_id, group_name, student_id, student_name, scores_json, field_source_json, total_score, group_total_score) "
            "VALUES (%s, %s, %s, %s, %s, %s, %s, %s)"
        )
        
        inserted_count = 0
        updated_count = 0
        skipped_count = 0
        
        # å½“å‰ä¸Šä¼ ä¸­æ¶‰åŠçš„å­—æ®µé›†åˆï¼ˆç”¨äºæ›¿æ¢æ¨¡å¼æ—¶ä¿ç•™å…¶ä»–excelçš„å­—æ®µï¼‰
        upload_field_set = set()
        for score_item in scores:
            for key in score_item.keys():
                if key not in ['group_name', 'student_id', 'student_name', 'group_total_score', 'æ€»åˆ†', 'total_score', 'total']:
                    upload_field_set.add(key)
        
        # ç¡®å®šå½“å‰Excelæ–‡ä»¶åï¼ˆå¦‚æœæœ‰å¤šä¸ªï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªï¼‰
        current_excel_filename = None
        if current_excel_filenames:
            current_excel_filename = list(current_excel_filenames)[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶å
        elif excel_file_name:
            current_excel_filename = excel_file_name
        
        for idx, score_item in enumerate(scores):
            group_name = score_item.get('group_name', '').strip()
            student_id = score_item.get('student_id')
            student_name = score_item.get('student_name', '').strip()
            if not student_name:
                skipped_count += 1
                print(f"[save_group_scores] è·³è¿‡ç¬¬{idx+1}æ¡è®°å½•ï¼šç¼ºå°‘å­¦ç”Ÿå§“å - score_item={score_item}")
                app_logger.warning(f"[save_group_scores] è·³è¿‡ç¬¬{idx+1}æ¡è®°å½•ï¼šç¼ºå°‘å­¦ç”Ÿå§“å - score_item={score_item}")
                continue
            
            # æ£€æŸ¥è¯¥å­¦ç”Ÿæ˜¯å¦å·²æœ‰æˆç»©è®°å½•
            check_sql = (
                "SELECT id, scores_json, field_source_json FROM ta_group_score_detail "
                "WHERE score_header_id = %s AND student_name = %s "
                "AND (%s IS NULL OR student_id = %s) "
                "LIMIT 1"
            )
            cursor.execute(check_sql, (score_header_id, student_name, student_id, student_id))
            existing_record = cursor.fetchone()
            
            # æ„å»ºJSONå¯¹è±¡ï¼ˆä½¿ç”¨å¤åˆé”®åï¼šå­—æ®µå_Excelæ–‡ä»¶åï¼‰
            # è¿™æ ·å¯ä»¥æ”¯æŒåŒä¸€å­—æ®µåæ¥è‡ªä¸åŒExcelæ–‡ä»¶çš„æƒ…å†µ
            scores_json = {}
            field_source_json = {}  # è®°å½•å­—æ®µååˆ°Excelæ–‡ä»¶åçš„æ˜ å°„ï¼ˆå¯é€‰ï¼‰
            total_score = None
            for key, value in score_item.items():
                if key not in ['group_name', 'student_id', 'student_name', 'group_total_score', 'æ€»åˆ†', 'total_score', 'total']:
                    if value is not None:
                        # ä½¿ç”¨å¤åˆé”®åï¼ˆå­—æ®µå_Excelæ–‡ä»¶åï¼‰æ¥ä¿å­˜ï¼Œé¿å…åŒåå­—æ®µè¦†ç›–
                        composite_key = f"{key}_{current_excel_filename}" if current_excel_filename else key
                        
                        try:
                            if isinstance(value, (int, float)):
                                scores_json[composite_key] = float(value)
                            elif isinstance(value, str) and value.strip():
                                scores_json[composite_key] = float(value.strip())
                            else:
                                scores_json[composite_key] = value
                        except (ValueError, TypeError):
                            scores_json[composite_key] = value
                        
                        # è®°å½•å­—æ®µæ¥æºæ˜ å°„ï¼ˆå¦‚æœåŒä¸€å­—æ®µåæ¥è‡ªå¤šä¸ªExcelï¼Œä½¿ç”¨æ•°ç»„ï¼‰
                        if key in field_source_json:
                            existing_source = field_source_json[key]
                            if isinstance(existing_source, str):
                                field_source_json[key] = [existing_source, current_excel_filename] if current_excel_filename else existing_source
                            elif isinstance(existing_source, list):
                                if current_excel_filename and current_excel_filename not in existing_source:
                                    existing_source.append(current_excel_filename)
                        else:
                            field_source_json[key] = current_excel_filename if current_excel_filename else key
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºæ€»åˆ†å­—æ®µ
                if (key == 'æ€»åˆ†' or key == 'total_score') and value is not None:
                    try:
                        total_score = float(value)
                    except (ValueError, TypeError):
                        pass
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ€»åˆ†å­—æ®µï¼Œè‡ªåŠ¨è®¡ç®—æ€»åˆ†
            if total_score is None:
                total_score = 0.0
                for key, value in scores_json.items():
                    if isinstance(value, (int, float)):
                        total_score += float(value)
                if total_score == 0.0:
                    total_score = None
            
            # è·å–å°ç»„æ€»åˆ†
            group_total_score = group_totals.get(group_name)
            
            # åœ¨è¿½åŠ æ¨¡å¼ä¸‹ï¼Œå¦‚æœè®°å½•å·²å­˜åœ¨ï¼Œåˆå¹¶JSONæ•°æ®ï¼ˆä¿ç•™æ—§å­—æ®µï¼Œæ·»åŠ æ–°å­—æ®µï¼‰
            # åœ¨æ›¿æ¢æ¨¡å¼ä¸‹ï¼Œä»…æ›¿æ¢æœ¬æ¬¡ä¸Šä¼ æ¶‰åŠçš„å­—æ®µï¼Œä¿ç•™å…¶ä»–excelçš„å­—æ®µ
            if operation_mode == 'append' and existing_record and existing_record.get('scores_json'):
                try:
                    existing_json = json.loads(existing_record['scores_json']) if isinstance(existing_record['scores_json'], str) else existing_record['scores_json']
                    # åˆå¹¶æ—¶ï¼Œå¤åˆé”®åä¸ä¼šå†²çªï¼ˆå› ä¸ºåŒ…å«Excelæ–‡ä»¶åï¼‰
                    merged_json = {**existing_json, **scores_json}
                    scores_json = merged_json
                    print(f"[save_group_scores] åˆå¹¶å·²æœ‰æˆç»©æ•°æ® - student_name={student_name}, æ—§å­—æ®µæ•°={len(existing_json)}, æ–°å­—æ®µæ•°={len(scores_json)}")
                    app_logger.info(f"[save_group_scores] åˆå¹¶å·²æœ‰æˆç»©æ•°æ® - student_name={student_name}")
                except (json.JSONDecodeError, TypeError) as e:
                    print(f"[save_group_scores] è§£æå·²æœ‰JSONå¤±è´¥ï¼Œä½¿ç”¨æ–°æ•°æ® - student_name={student_name}, error={e}")
                    app_logger.warning(f"[save_group_scores] è§£æå·²æœ‰JSONå¤±è´¥ï¼Œä½¿ç”¨æ–°æ•°æ® - student_name={student_name}, error={e}")
            elif operation_mode == 'replace' and existing_record and existing_record.get('scores_json'):
                try:
                    existing_json = json.loads(existing_record['scores_json']) if isinstance(existing_record['scores_json'], str) else existing_record['scores_json']
                    # æ›¿æ¢æ¨¡å¼ä¸‹ï¼Œä»…åˆ é™¤å½“å‰Excelæ–‡ä»¶çš„å­—æ®µï¼Œä¿ç•™å…¶ä»–Excelçš„å­—æ®µ
                    # ä¿ç•™ä¸ä»¥å½“å‰Excelæ–‡ä»¶åç»“å°¾çš„å­—æ®µï¼ˆå³å…¶ä»–Excelçš„å­—æ®µï¼‰
                    if current_excel_filename:
                        preserved = {k: v for k, v in existing_json.items() if not k.endswith(f"_{current_excel_filename}")}
                    else:
                        # å¦‚æœæ²¡æœ‰Excelæ–‡ä»¶åï¼Œä¿ç•™ä¸åœ¨æœ¬æ¬¡ä¸Šä¼ å­—æ®µé›†ä¸­çš„å­—æ®µ
                        preserved = {k: v for k, v in existing_json.items() if k not in upload_field_set}
                    scores_json = {**preserved, **scores_json}
                    print(f"[save_group_scores] æ›¿æ¢æ¨¡å¼ä¿ç•™å…¶ä»–excelå­—æ®µ - student_name={student_name}, ä¿ç•™å­—æ®µæ•°={len(preserved)}, æ–°å­—æ®µæ•°={len(scores_json)}")
                    app_logger.info(f"[save_group_scores] æ›¿æ¢æ¨¡å¼ä¿ç•™å…¶ä»–excelå­—æ®µ - student_name={student_name}")
                except (json.JSONDecodeError, TypeError) as e:
                    print(f"[save_group_scores] è§£æå·²æœ‰JSONå¤±è´¥ï¼Œä½¿ç”¨æ–°æ•°æ® - student_name={student_name}, error={e}")
                    app_logger.warning(f"[save_group_scores] è§£æå·²æœ‰JSONå¤±è´¥ï¼Œä½¿ç”¨æ–°æ•°æ® - student_name={student_name}, error={e}")
            
            # åœ¨è¿½åŠ æ¨¡å¼ä¸‹ï¼Œåˆå¹¶å­—æ®µæ¥æºæ˜ å°„
            existing_field_source_json = {}
            if existing_record and existing_record.get('field_source_json'):
                try:
                    existing_field_source_json = json.loads(existing_record['field_source_json']) if isinstance(existing_record['field_source_json'], str) else existing_record['field_source_json']
                except (json.JSONDecodeError, TypeError):
                    existing_field_source_json = {}
            
            if operation_mode == 'append' and existing_record:
                # åˆå¹¶å­—æ®µæ¥æºæ˜ å°„
                field_source_json = {**existing_field_source_json, **field_source_json}
            elif operation_mode == 'replace' and existing_record:
                # æ›¿æ¢æ¨¡å¼ä¸‹ï¼Œåˆ é™¤å½“å‰Excelçš„å­—æ®µæ˜ å°„ï¼Œä¿ç•™å…¶ä»–çš„
                preserved_sources = {k: v for k, v in existing_field_source_json.items() 
                                    if (isinstance(v, str) and v != current_excel_filename) or
                                       (isinstance(v, list) and current_excel_filename not in v)}
                field_source_json = {**preserved_sources, **field_source_json}
            
            # å°†scores_jsonå’Œfield_source_jsonè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
            scores_json_str = json.dumps(scores_json, ensure_ascii=False)
            field_source_json_str = json.dumps(field_source_json, ensure_ascii=False) if field_source_json else None
            
            is_update = existing_record is not None
            action = "æ›´æ–°" if is_update else "æ’å…¥"
            print(f"[save_group_scores] {action}ç¬¬{idx+1}æ¡æˆç»© - student_name={student_name}, group_name={group_name}, scores_json={scores_json_str}, field_source_json={field_source_json_str}, total_score={total_score}, group_total_score={group_total_score}")
            app_logger.info(f"[save_group_scores] {action}ç¬¬{idx+1}æ¡æˆç»© - student_name={student_name}, group_name={group_name}, total_score={total_score}, group_total_score={group_total_score}")
            
            try:
                if existing_record:
                    update_detail_sql = (
                        "UPDATE ta_group_score_detail "
                        "SET group_name = %s, scores_json = %s, field_source_json = %s, total_score = %s, group_total_score = %s, updated_at = NOW() "
                        "WHERE id = %s"
                    )
                    cursor.execute(update_detail_sql, (
                        group_name,
                        scores_json_str,
                        field_source_json_str,
                        total_score,
                        group_total_score,
                        existing_record['id']
                    ))
                    updated_count += 1
                else:
                    cursor.execute(insert_detail_sql, (
                        score_header_id,
                        group_name,
                        student_id,
                        student_name,
                        scores_json_str,
                        field_source_json_str,
                        total_score,
                        group_total_score
                    ))
                    inserted_count += 1
            except Exception as insert_error:
                print(f"[save_group_scores] ç¬¬{idx+1}æ¡æˆç»©{action}å¤±è´¥ - student_name={student_name}, error={insert_error}")
                app_logger.error(f"[save_group_scores] ç¬¬{idx+1}æ¡æˆç»©{action}å¤±è´¥ - student_name={student_name}, error={insert_error}", exc_info=True)
                raise

        print(f"[save_group_scores] æˆç»©æ˜ç»†å¤„ç†å®Œæˆ - æ’å…¥={inserted_count}, æ›´æ–°={updated_count}, è·³è¿‡={skipped_count}, æ€»è®¡={len(scores)}")
        app_logger.info(f"[save_group_scores] æˆç»©æ˜ç»†å¤„ç†å®Œæˆ - æ’å…¥={inserted_count}, æ›´æ–°={updated_count}, è·³è¿‡={skipped_count}, æ€»è®¡={len(scores)}")
        
        print(f"[save_group_scores] å¼€å§‹æäº¤äº‹åŠ¡")
        app_logger.info(f"[save_group_scores] å¼€å§‹æäº¤äº‹åŠ¡")
        connection.commit()
        total_processed = inserted_count + updated_count
        print(f"[save_group_scores] äº‹åŠ¡æäº¤æˆåŠŸ - score_header_id={score_header_id}, æ’å…¥={inserted_count}, æ›´æ–°={updated_count}, åˆ é™¤å­¦ç”Ÿ={deleted_student_count}, æ€»è®¡={total_processed}")
        app_logger.info(f"[save_group_scores] äº‹åŠ¡æäº¤æˆåŠŸ - score_header_id={score_header_id}, æ’å…¥={inserted_count}, æ›´æ–°={updated_count}, åˆ é™¤å­¦ç”Ÿ={deleted_student_count}, æ€»è®¡={total_processed}")
        return { 
            'success': True, 
            'score_header_id': score_header_id, 
            'inserted_count': inserted_count, 
            'updated_count': updated_count,
            'deleted_student_count': deleted_student_count,
            'message': 'ä¿å­˜æˆåŠŸ' 
        }
    except mysql.connector.Error as e:
        if connection and connection.is_connected():
            print(f"[save_group_scores] æ•°æ®åº“é”™è¯¯ï¼Œå›æ»šäº‹åŠ¡ - error={e}")
            app_logger.error(f"[save_group_scores] æ•°æ®åº“é”™è¯¯ï¼Œå›æ»šäº‹åŠ¡ - error={e}")
            connection.rollback()
        else:
            print(f"[save_group_scores] æ•°æ®åº“é”™è¯¯ï¼Œè¿æ¥å·²æ–­å¼€ - error={e}")
            app_logger.error(f"[save_group_scores] æ•°æ®åº“é”™è¯¯ï¼Œè¿æ¥å·²æ–­å¼€ - error={e}")
        import traceback
        traceback_str = traceback.format_exc()
        print(f"[save_group_scores] é”™è¯¯å †æ ˆ:\n{traceback_str}")
        app_logger.error(f"[save_group_scores] é”™è¯¯å †æ ˆ:\n{traceback_str}")
        return { 'success': False, 'score_header_id': None, 'inserted_count': 0, 'message': f'æ•°æ®åº“é”™è¯¯: {e}' }
    except Exception as e:
        if connection and connection.is_connected():
            print(f"[save_group_scores] æœªçŸ¥é”™è¯¯ï¼Œå›æ»šäº‹åŠ¡ - error={e}")
            app_logger.error(f"[save_group_scores] æœªçŸ¥é”™è¯¯ï¼Œå›æ»šäº‹åŠ¡ - error={e}")
            connection.rollback()
        else:
            print(f"[save_group_scores] æœªçŸ¥é”™è¯¯ï¼Œè¿æ¥å·²æ–­å¼€ - error={e}")
            app_logger.error(f"[save_group_scores] æœªçŸ¥é”™è¯¯ï¼Œè¿æ¥å·²æ–­å¼€ - error={e}")
        import traceback
        traceback_str = traceback.format_exc()
        print(f"[save_group_scores] é”™è¯¯å †æ ˆ:\n{traceback_str}")
        app_logger.error(f"[save_group_scores] é”™è¯¯å †æ ˆ:\n{traceback_str}")
        return { 'success': False, 'score_header_id': None, 'inserted_count': 0, 'message': f'æœªçŸ¥é”™è¯¯: {e}' }
    finally:
        if connection and connection.is_connected():
            connection.close()
            app_logger.info("Database connection closed after saving group scores.")


